{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Particles Diffusion physics\n",
    "\n",
    "NOTE: each plot should have a x-label, a y-label and a legend if multiple lines on the same plot.\n",
    "\n",
    "## 1 First look at the problem\n",
    "\n",
    "### 1.1 Introduction to diffusion\n",
    "\n",
    "We are going to look at the concept of [diffusion](https://en.wikipedia.org/wiki/Diffusion) as a random process where the probability distribution (PDF) of particle positions is following the dynamic of the diffusion equation with dimension $d$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial P(r,t)}{\\partial t} = \\frac{1}{r^{d-1}}\\frac{\\partial}{\\partial r}\\left(r^{d-1}K(r)\\frac{\\partial P(r,t)}{\\partial r}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $K(r)$ is the diffusivity (or the diffusion constant if independent of $r$ or $t$) and $r=\\sqrt{\\sum_{i=1}^d x_i^2}$ is the norm of the position vector $\\mathbf{r}=\\left(\\begin{matrix}\n",
    "  x_1  \\\\\n",
    "  x_2  \\\\\n",
    "  \\vdots  \\\\\n",
    "  x_d\n",
    " \\end{matrix}\\right)$. $P(r,t)$ satisfies\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{0}^{\\infty}r^{d-1}P(r,t) = 1.\n",
    "\\end{equation}\n",
    "\n",
    "as normalization condition. In the following we are going to look at the $d=1$ for the sake of simplicity.\n",
    "\n",
    "### 1.2 Power law diffusity: an interesting dynamic\n",
    "\n",
    "A diffusivity that is dependent of the position norm generates a very rich physics. We are going to consider the case of a power law diffusity:\n",
    "\n",
    "\\begin{equation}\n",
    "K(r) = Dr^\\alpha, \\,\\,\\, 0<\\alpha<2\n",
    "\\end{equation}\n",
    "\n",
    "This diffusivity induces a time evolution\n",
    "\n",
    "\\begin{equation}\n",
    "\\langle r^2(t)\\rangle \\sim g\\left(Dt\\right)^{2/\\gamma}, \\,\\,\\,\\, g=\\frac{\\gamma^{4/\\gamma}\\Gamma\\left(\\frac{d+2}{\\gamma}\\right)}{\\Gamma\\left(\\frac{d}{\\gamma}\\right)}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Gamma(x)$ is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function) and $\\gamma=2-\\alpha$. The PDF has a stretched-exponential distribution\n",
    "\n",
    "\\begin{equation}\n",
    "P(r,t) = \\frac{1}{\\langle r^2(t)\\rangle^{d/2}}\\exp\\left[-A\\left(\\frac{r}{\\sqrt{\\langle r^2(t)\\rangle}}\\right)^\\gamma + B\\right]\n",
    "\\end{equation}\n",
    "\n",
    "with\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A&=&\\left[\\frac{\\Gamma\\left(\\frac{d+2}{\\gamma}\\right)}{\\Gamma\\left(\\frac{d}{\\gamma}\\right)}\\right]^{\\gamma/2}\\\\\n",
    "B&=&\\log\\left[\\gamma\\frac{\\Gamma\\left(\\frac{d+2}{\\gamma}\\right)^{d/2}}{\\Gamma\\left(\\frac{1}{\\gamma}\\right)^{(d+2)/2}}\\right]\n",
    "\\end{eqnarray}\n",
    "\n",
    "In our case are going to work in the specific case of $d=1$ and $\\alpha=0$ for simplicity.\n",
    "\n",
    "### 1.3 Solving the diffusion equation using a Monte Carlo method\n",
    "\n",
    "The above diffusion equation has an equivalent [Ito](https://en.wikipedia.org/wiki/It%C3%B4_calculus) stochastic differential equation\n",
    "\n",
    "\\begin{equation}\n",
    "dx = \\sqrt{2K}dW\n",
    "\\end{equation}\n",
    "\n",
    "with $W$ being a [Wiener process](https://en.wikipedia.org/wiki/Wiener_process) or Brownian motion. We can numerically integrate the stochastic equations using the [Euler-Maruyama](https://en.wikipedia.org/wiki/Euler%E2%80%93Maruyama_method) scheme:\n",
    "\n",
    "\\begin{equation}\n",
    "x(T_i) = x(T_{i-1}) + \\sqrt{2K\\Delta T}N_{T}\n",
    "\\end{equation}\n",
    "where $\\Delta T = T_n - T_{n-1}$ is a discretized time increment and $N_{T}$ is a standard normal random variable.\n",
    "\n",
    "## 1.4 Simulating to create our data\n",
    "\n",
    "Let's make this simulation happen! We are going to write a function that generates particles paths under this diffusive dynamic. The output of this function will be a data frame with each row representing a particle and each column, a specific point in time. The values of this data frame will be the position of the particles at the different point in time. \n",
    "\n",
    "Before writing this function, we are going explore how to do it.\n",
    "\n",
    ">- First, create a data frame with 1000 columns (representing the points in time) and column names `T_0`, `T_1`, ..., `T_999`. We are going to use 100 rows (100 particles) for simplicity. \n",
    "- Fill this data frame with a normal noise in each cell using [`numpy.random.normal`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html).\n",
    "- set the first column to 0 (start at $x=0$).\n",
    "- Use the pandas function [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.cumsum.html) to generate a cumulative sum of the columns.\n",
    "\n",
    "Doing so, you are creating stochastic paths for 100 particles for 1000 different time points with $K=1$ and $\\Delta T=1$. It should look something like:\n",
    "\n",
    "<img src=\"images/initial_stck_path.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO: create a data frame with stochastic paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize those stochastic paths\n",
    "\n",
    ">- Use [`sample`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html) to sample 10 samples\n",
    "- Use [`transpose`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.transpose.html) to transpose the index and columns\n",
    "- Use [`reset_index(drop=True)`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html) to remove the index\n",
    "- Use [`plot`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) to plot the resulting samples\n",
    "- You can set the different graph attributes such that\n",
    "```\n",
    "ax = df.plot(fontsize=20)\n",
    "ax.set_xlabel(\"Time\", fontsize=25)\n",
    "ax.set_ylabel(\"position\", fontsize=25)\n",
    "ax.legend(fontsize=20)\n",
    "```\n",
    "\n",
    "You should see something like\n",
    "\n",
    "<img src=\"images/paths.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot 10 sample paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we understand how to generate stochastic paths, let's write this function `run_simulation`. Use the different arguments $K$, $\\Delta T$, the number of particles `num_particles` and the number of time steps `max_time` to return the desired data frame according to\n",
    "\\begin{equation}\n",
    "x(T_i) = x(T_{i-1}) + \\sqrt{2K\\Delta T}N_{T}\n",
    "\\end{equation}\n",
    "You can use [`numpy.sqrt`](https://www.google.com/search?q=numpy+sart&oq=numpy+sart&aqs=chrome..69i57j0l5.2967j0j4&sourceid=chrome&ie=UTF-8#q=numpy+sqrt) is you need. \n",
    "\n",
    "Once again you get something similar to from the function `run_simulation`\n",
    "\n",
    "<img src=\"images/diffusion_filled_df.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO: write a function that create a data frame with stochastic paths\n",
    "def run_simulation(num_particle, max_time, K, deltaT):\n",
    "    ## YOUR CODE\n",
    "    raise NotImplementedError\n",
    "\n",
    "diffusion_filled_df = run_simulation(100, 1000, 2, 1)\n",
    "diffusion_filled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Studying the data\n",
    "\n",
    "Up to now, everything was a pretext to create some data to study. Let's try to understand a bit more the physics of those particles. \n",
    "\n",
    "### 2.1 The dispersion\n",
    "\n",
    "We are going to start by computing the dispersion $\\langle \\Vert \\mathbf{r}(t)\\Vert^2\\rangle$ at different points in time:\n",
    "\n",
    ">- Let's create a dataframe `dispersion_df` by taking the square the elements of the resulting dataframe using the [`pow`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pow.html) function\n",
    "- We now take the mean ([`mean`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html)) and standard deviation ([`std`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.std.html)) of every column. To apply two functions at once on a column you can use the apply function such that:\n",
    "\n",
    "```\n",
    "df.apply(lambda r: pd.Series({'mean': r.mean(), 'std': r.std()})).transpose()\n",
    "```\n",
    "\n",
    "You should get something like\n",
    "\n",
    "<img src=\"images/dispersion.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TODO: create a dataframe `dispersion_df` by taking the square the elements\n",
    "\n",
    "# TODO: compute the mean and standard deviation of every column of the dispersion_df dataframe\n",
    "dispersion_avg = ## YOUR CODE\n",
    "dispersion_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The confidence interval\n",
    "\n",
    "Because we computed the sample standard deviation, we can estimate the [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval) of the mean. Under the assumption that $\\Vert \\mathbf{r}(t)\\Vert^2$ is normal distributed, we estimate the confidence interval such that\n",
    "\n",
    "\\begin{equation}\n",
    "\\left(\\left\\langle\\Vert\\mathbf{r}(t)\\Vert^2\\right\\rangle - c\\frac{S}{\\sqrt{L}},\\left\\langle\\Vert\\mathbf{r}(t)\\Vert^2\\right\\rangle + c\\frac{S}{\\sqrt{L}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $S$ is the estimate of the standard deviation, $L$ is the number of samples used (here the number of particles) and $c$ is a parameter we chose depending on the on confidence level on the average we require. Because the standard deviation is unknown (we are estimating it), $c$ is chosen according to the [Student's t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution). For example, when $L$ is very large, $c\\simeq1.96$ gives a 95% confidence level for this confidence interval. \n",
    "\n",
    "### 2.3 Plotting the dispersion\n",
    "\n",
    "We are now going to plot the dispersion with matplotlib. We need to create a time array $T$ to represente the time:\n",
    "\n",
    ">- Create the time array $T$ using the `range` function or the [`np.arange`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html) function\n",
    "- Use the [`errorbar`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.errorbar.html) function with the $T$ array on the x-axis and `dispersion_avg[\"mean\"]` on the y-axis. Use `1.96*dispersion_avg[\"std\"]` divided by the square-root of the number of particles for the `yerr` argument. \n",
    "- use the argument `errorevery` of `errorbar` to decrease the amount of error bars plotted.\n",
    "- Set the line width to 3 using the `lw` argument\n",
    "- Set the color of the line to blue by using the `color` argument\n",
    "- Set the label of the curve to \"Dispersion\"\n",
    "- Set the size of the figure to `[10, 8]` using `plt.rcParams[\"figure.figsize\"] = [10, 8]`\n",
    "- Set the x and y tick label sizes to 20 using `plt.rc('xtick', labelsize=20)`\n",
    "- Set x label to \"Time\" with font size 25 using `plt.xlabel(\"Time\", fontsize=25)` and the y label to \"$\\left\\langle\\Vert\\mathbf{r}(t)\\Vert^2\\right\\rangle$\" with font size 25. You can write math instead of text by using `r\"$some math$\"`.\n",
    "- Set the x and y limits by using `plt.xlim(0,1000)` to the min and max of `T` and the dispersion \n",
    "- Write out the label of the curve using `plt.legend()` with font size set to 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create the time array\n",
    "T = ## YOUR CODE\n",
    "\n",
    "# TODO: Set the size of the figure to [10, 8]\n",
    "\n",
    "# TODO: Set the x and y tick label sizes to 20\n",
    "\n",
    "# TODO: plot\n",
    "\n",
    "# TODO: Set the x and y limits\n",
    "\n",
    "# TODO: Set the x and y labels\n",
    "\n",
    "# TODO: write the legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the confindence interval negligeable? \n",
    "\n",
    ">- Repeat the simulation process until you find a number of particles that yield negligeable confidence interval. \n",
    "- Replot the previous curve for 3 different values of `num_particles` to highlight the evolution of the errobars when the number of particles is increased.\n",
    "\n",
    "You should get something like\n",
    "\n",
    "<img src=\"images/dispersion_number.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: choose 3 differents num_particles, recompute the dispersion and those 3 on the same graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">So what value of `num_particles` seems acceptable to present a statistically converged averages?\n",
    "\n",
    "Remember that \n",
    "\n",
    "\\begin{equation}\n",
    "\\langle r^2(t)\\rangle \\sim g\\left(Dt\\right)^{2/\\gamma}, \\,\\,\\,\\, g=\\frac{\\gamma^{4/\\gamma}\\Gamma\\left(\\frac{d+2}{\\gamma}\\right)}{\\Gamma\\left(\\frac{d}{\\gamma}\\right)}\n",
    "\\end{equation}\n",
    "\n",
    "for \n",
    "\n",
    "\\begin{equation}\n",
    "K(r) = Dr^\\alpha, \\,\\,\\, 0\\leq\\alpha<2\n",
    "\\end{equation}\n",
    "\n",
    ">- What is the value of $\\gamma$ here?\n",
    "- Write function that compute $g$ given $\\gamma$ and $d$. Use the [`scipy.special.gamma`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.special.gamma.html) function and [`np.power`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.power.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import gamma as G\n",
    "\n",
    "# TODO: write a function that compute g\n",
    "def g(gamma, d):\n",
    "    ## YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Plot `T` versus `dispersion_avg[\"mean\"] / T` with label \"Dispersion\"\n",
    "- Add an horizontal line to the graph using [`axhline`](https://matplotlib.org/devdocs/api/_as_gen/matplotlib.axes.Axes.axhline.html) with argument `y = g(gamma, d) * K, color=\"r\", lw=2, ls=\"--\"` and label \"Diffusive regime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot T versus dispersion_avg[\"mean\"] / T\n",
    "\n",
    "# TODO: add horizontal line for the diffusive regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 The probability distribution\n",
    "\n",
    "We now going to estimate the probability distribution $P(r,t)$ at different times. To estimate a probability distribution at $r_i$ and $t=t^*$, we can simply count the number of samples in a small region $\\Delta r_i$ around $r_i$. Because we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{0}^{\\infty}r^{d-1}P(r,t) = 1\n",
    "\\end{equation}\n",
    "\n",
    "We need our estimate $\\hat{P}(r_i,t^*)$ of the probabitity distribution \n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^{M}\\hat{P}(r_i,t^*)\\Delta r_i = 1\n",
    "\\end{equation}\n",
    "\n",
    "where $M$ is the number of discretized space increments $\\Delta r_i$. Therefore we can estimate \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{P}(r_i,t^*) = \\frac{n}{N\\Delta r_i}\n",
    "\\end{equation}\n",
    "\n",
    "where $n$ is the number of samples in the interval $\\Delta r_i$ at time $t^*$ and $N$ is the total number of samples. Let's check that this work\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{i=1}^{M}\\hat{P}(r_i,t^*)\\Delta r_i = \\sum_{i=1}^{M}\\frac{n}{N\\Delta r_i}\\Delta r_i= \\frac{1}{N}\\sum_{i=1}^{M}n =1\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We are going to write a function that compute the probability distribution. This function will return the probability distribution along with the a set of $r_i$:\n",
    "\n",
    ">- use the pandas [`qcut`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html) function to cut in quantiles the absolute values of the positions in `diffusion_filled_df` for a specific column. Use the argument `q` to choose the number of cuts and use `retbins=True` to return the bins into a `bins` variable. Use this function to create a new column \"cut\" in `diffusion_filled_df`\n",
    "- You can now create the $\\Delta r_i$ intervals by using the trick `deltaR = bins[1:] - bins[:-1]` \n",
    "- group by using the pandas `groupby` this new column \"cut\" to count using the function [`count`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html)\n",
    "- divide the resulting quantity by `deltaR * num_particles`. At that point, you obtained a statistical estimation of the probability distribution.\n",
    "- group by using the pandas `groupby` this new column \"cut\" and use the pandas `apply` method to return the median of the absolute value of the positions at that point in time. This gives you the set of $r_i$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_prob_distribution(absolute_position, num_cuts):\n",
    "    \n",
    "    # TODO: cut absolute_position using qcut and num_cuts\n",
    "    absolute_position_copy[\"cut\"], bins = ## YOUR CODE\n",
    "    \n",
    "    # TODO: compute deltaR\n",
    "    deltaR = ## YOUR CODE\n",
    "    \n",
    "    # TODO: compute the counts per cuts of the column \"cut\"\n",
    "    counts = ## YOUR CODE\n",
    "    \n",
    "    # TODO: normalize the counts to get the probability distribution\n",
    "    pdf = ## YOUR CODE\n",
    "    \n",
    "    # TODO: compute the median per cuts of the column \"cut\" of the absolute position\n",
    "    r = ## YOUR CODE\n",
    "    \n",
    "    return pdf, r\n",
    "\n",
    "compute_prob_distribution(diffusion_filled_df3[\"T_999\"].abs(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compare the result of this function with the theoretical results. Remember that \n",
    "\n",
    "\\begin{equation}\n",
    "P(r,t) = \\frac{1}{\\langle r^2(t)\\rangle^{d/2}}\\exp\\left[-A\\left(\\frac{r}{\\sqrt{\\langle r^2(t)\\rangle}}\\right)^\\gamma + B\\right]\n",
    "\\end{equation}\n",
    "\n",
    "with\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A&=&\\left[\\frac{\\Gamma\\left(\\frac{d+2}{\\gamma}\\right)}{\\Gamma\\left(\\frac{d}{\\gamma}\\right)}\\right]^{\\gamma/2}\\\\\n",
    "B&=&\\log\\left[\\gamma\\frac{\\Gamma\\left(\\frac{d+2}{\\gamma}\\right)^{d/2}}{\\Gamma\\left(\\frac{1}{\\gamma}\\right)^{(d+2)/2}}\\right]\n",
    "\\end{eqnarray}\n",
    "\n",
    "- Write a function `A(gamma, d)`\n",
    "- Write a function `B(gamma, d)`\n",
    "- Write a function `dispersion` that returns $g\\left(Dt\\right)^{2/\\gamma}$. You already wrote the function that computes $g$.\n",
    "- Write a function `pdf(gamma, d, r, t, D)` with `r` being an array of absolute positions $r$ and `t` the time the pdf is computed. Use the function [`np.exp`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: write a function that computes A\n",
    "def A(gamma, d):\n",
    "    ## YOUR CODE\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: write a function that computes B\n",
    "def B(gamma, d):\n",
    "    ## YOUR CODE\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: write a function that computes the dispersion\n",
    "def dispersion(gamma, d, t, D):\n",
    "    ## YOUR CODE\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: write a function that computes the theoretical PDF\n",
    "def pdf(gamma, d, r, t, D):\n",
    "    ## YOUR CODE\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Plot the estimated probability distribution at the same time that for the theoretical pdf for a specific time\n",
    "\n",
    "You should get something like\n",
    "<img src=\"images/pdfs.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the estimated pdf and use the r array to show the theoretical one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 The self-similarity of the probability distribution\n",
    "\n",
    "Notice that \n",
    "\n",
    "\\begin{equation}\n",
    "\\log\\left(P(r,t)\\langle r^2(t)\\rangle^{d/2}\\right) = -A\\left(\\frac{r}{\\sqrt{\\langle r^2(t)\\rangle}}\\right)^\\gamma + B\n",
    "\\end{equation}\n",
    "\n",
    "If we look at the relationship of $Y=\\log\\left(P(r,t)\\langle r^2(t)\\rangle^{d/2}\\right)$ versus $X=\\left(\\frac{r}{\\sqrt{\\langle r^2(t)\\rangle}}\\right)^\\gamma$ for any $r$ and $t$, we should observe a linear relationship.\n",
    "\n",
    "> Using your statistical estimation of the the PDF, plot on the same graph $\\log\\left(P(r,t)\\langle r^2(t)\\rangle^{1/2}\\right)$ versus $\\left(\\frac{r}{\\sqrt{\\langle r^2(t)\\rangle}}\\right)^\\gamma$ for:\n",
    "- t = 199\n",
    "- t = 399\n",
    "- t = 599\n",
    "- t = 799\n",
    "- t = 999\n",
    "\n",
    "using your statistical estimation of the the PDF.\n",
    "\n",
    "You can use [`np.log`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.log.html). You should get something like\n",
    "<img src=\"images/self_sim.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:Plot the rescaled estimated pdf for t = 199, 399, 599, 799, 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to work but the last points seem misestimated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Statistical tests\n",
    "\n",
    "###  3.1 t-test\n",
    "\n",
    "Intuitively we can see that the variable $\\frac{\\Vert \\mathbf{r}(t)\\Vert}{\\sqrt{\\langle r^2(t)\\rangle}}$ has a probability distribution that is independent of the time. Let's test this hypothesis by doing a [t-test](https://en.wikipedia.org/wiki/Student%27s_t-test) statistics.\n",
    "\n",
    ">- take 2 different times (columns) in `diffusion_filled_df` and rescale the absolute values by the corresponding `np.sqrt(dispersion_avg.loc[time, \"mean\"])`\n",
    "- Use [`scipy.stats.ttest_ind`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) to compare the statistics of the 2 samples\n",
    "- What can we conclude from the [p-value](https://en.wikipedia.org/wiki/P-value)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# TODO: choose 2 times to perform a t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually look at all the sample by performing a more general analysis of variance or [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance) for all the times at once\n",
    "\n",
    ">- Divide `diffusion_filled_df` by `dispersion_avg3[\"mean\"]`\n",
    "- Use the function [`stats.f_oneway`](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.f_oneway.html) to perform the ANOVA with a [f-distribution](https://en.wikipedia.org/wiki/F-distribution)\n",
    "- You will need to use the underlying numpy array of the data frame (`.values`), then avoid the first column (`[:,1:]`) (because it was all 0) and take the transpose (`.T`). The resulting array is a list of lists and you can [unpack](https://stackoverflow.com/questions/3480184/unpack-a-list-in-python) it using `*(df.values[:,1:].T)`.\n",
    "- What can you conclude from the p-value? Can you show that it was expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: perform an ANOVA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
