{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 1: Scrapping the web, Nobel Price Laureates\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We are going to scrape the web to extract information about the different Nobel price laureates. This homework is designed to get you familiarized with some of the python data structures.\n",
    "\n",
    "## Getting the data\n",
    "\n",
    "We are going to get the data of all the [Nobel price laureates in Physics from Wikipedia](https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Physics). I wrote a small web parser to parse the table in a pandas dataframe. It is not important that you fully understand how it works but it does not hurt to try! I am using the [`httplib2`](https://github.com/httplib2/httplib2) and [`bs4`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) libraries. Be sure to download them:\n",
    "\n",
    ">In a terminal window type\n",
    "```\n",
    "source activate YOUR_ENVIRONMENT\n",
    "pip install httplib2\n",
    "pip install bs4\n",
    "source deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Laureate[A]</th>\n",
       "      <th>Country[B]</th>\n",
       "      <th>Rationale[C]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Wilhelm Conrad Röntgen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>\"in recognition of the extraordinary services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1902</td>\n",
       "      <td>Hendrik Lorentz</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>\"in recognition of the extraordinary service t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pieter Zeeman</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903</td>\n",
       "      <td>Antoine Henri Becquerel</td>\n",
       "      <td>France</td>\n",
       "      <td>\"for his discovery of spontaneous radioactivit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pierre Curie</td>\n",
       "      <td>France</td>\n",
       "      <td>\"for their joint researches on the radiation p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Skłodowska-Curie</td>\n",
       "      <td>Poland\\n France</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1904</td>\n",
       "      <td>Lord Rayleigh</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"for his investigations of the densities of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1905</td>\n",
       "      <td>Philipp Eduard Anton von Lenard</td>\n",
       "      <td>Austria-Hungary\\n Germany</td>\n",
       "      <td>\"for his work on cathode rays\"[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1906</td>\n",
       "      <td>Joseph John Thomson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"for his theoretical and experimental investig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1907</td>\n",
       "      <td>Albert Abraham Michelson</td>\n",
       "      <td>United States\\n Poland</td>\n",
       "      <td>\"for his optical precision instruments and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1908</td>\n",
       "      <td>Gabriel Lippmann</td>\n",
       "      <td>France</td>\n",
       "      <td>\"for his method of reproducing colours photogr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1909</td>\n",
       "      <td>Guglielmo Marconi</td>\n",
       "      <td>Italy</td>\n",
       "      <td>\"for their contributions to the development of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Karl Ferdinand Braun</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1910</td>\n",
       "      <td>Johannes Diderik van der Waals</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>\"for his work on the equation of state for gas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1911</td>\n",
       "      <td>Wilhelm Wien</td>\n",
       "      <td>Germany</td>\n",
       "      <td>\"for his discoveries regarding the laws govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1912</td>\n",
       "      <td>Nils Gustaf Dalén</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>\"for his invention of automatic valves designe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1913</td>\n",
       "      <td>Heike Kamerlingh-Onnes</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>\"for his investigations on the properties of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1914</td>\n",
       "      <td>Max von Laue</td>\n",
       "      <td>Germany</td>\n",
       "      <td>\"For his discovery of the diffraction of X-ray...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1915</td>\n",
       "      <td>William Henry Bragg</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"For their services in the analysis of crystal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>William Lawrence Bragg</td>\n",
       "      <td>Australia\\n United Kingdom</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1916</td>\n",
       "      <td>Not awarded World War I</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1917</td>\n",
       "      <td>Charles Glover Barkla</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\"For his discovery of the characteristic Röntg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1918</td>\n",
       "      <td>Max Planck</td>\n",
       "      <td>Germany</td>\n",
       "      <td>\"for the services he rendered to the advanceme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1919</td>\n",
       "      <td>Johannes Stark</td>\n",
       "      <td>Germany</td>\n",
       "      <td>\"for his discovery of the Doppler effect in ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1920</td>\n",
       "      <td>Charles Édouard Guillaume</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>\"for the service he has rendered to precision ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1921</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>Germany\\n  Switzerland</td>\n",
       "      <td>\"for his services to theoretical physics, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1922</td>\n",
       "      <td>Niels Bohr</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>\"for his services in the investigation of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1923</td>\n",
       "      <td>Robert Andrews Millikan</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"for his work on the elementary charge of elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1924</td>\n",
       "      <td>Manne Siegbahn</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>\"for his discoveries and research in the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1925</td>\n",
       "      <td>James Franck</td>\n",
       "      <td>Germany</td>\n",
       "      <td>\"for their discovery of the laws governing the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2005</td>\n",
       "      <td>Roy J. Glauber</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"for his contribution to the quantum theory of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>NaN</td>\n",
       "      <td>John L. Hall</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"for their contributions to the development of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Theodor W. Hänsch</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2006</td>\n",
       "      <td>John C. Mather</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"for their discovery of the blackbody form and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>George F. Smoot</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2007</td>\n",
       "      <td>Albert Fert</td>\n",
       "      <td>France</td>\n",
       "      <td>\"for the discovery of giant magnetoresistance\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Grünberg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2008</td>\n",
       "      <td>Makoto Kobayashi</td>\n",
       "      <td>Japan</td>\n",
       "      <td>\"for the discovery of the origin of the broken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Toshihide Maskawa</td>\n",
       "      <td>Japan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yoichiro Nambu</td>\n",
       "      <td>Japan\\n United States</td>\n",
       "      <td>\"for the discovery of the mechanism of spontan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2009</td>\n",
       "      <td>Charles K. Kao</td>\n",
       "      <td>Hong Kong\\n United Kingdom\\n United States</td>\n",
       "      <td>\"for groundbreaking achievements concerning th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Willard S. Boyle</td>\n",
       "      <td>Canada\\n United States</td>\n",
       "      <td>\"for the invention of an imaging semiconductor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NaN</td>\n",
       "      <td>George E. Smith</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2010</td>\n",
       "      <td>Andre Geim</td>\n",
       "      <td>Russia\\n United Kingdom\\n Netherlands</td>\n",
       "      <td>\"for groundbreaking experiments regarding the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Konstantin Novoselov</td>\n",
       "      <td>Russia\\n United Kingdom</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2011</td>\n",
       "      <td>Saul Perlmutter</td>\n",
       "      <td>United States</td>\n",
       "      <td>\"for the discovery of the accelerating expansi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Brian P. Schmidt</td>\n",
       "      <td>Australia\\n United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam G. Riess</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2012</td>\n",
       "      <td>Serge Haroche</td>\n",
       "      <td>France</td>\n",
       "      <td>\"for ground-breaking experimental methods that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>David J. Wineland</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2013</td>\n",
       "      <td>François Englert</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>\"for the theoretical discovery of a mechanism ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter Higgs</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2014</td>\n",
       "      <td>Isamu Akasaki</td>\n",
       "      <td>Japan</td>\n",
       "      <td>\"for the invention of efficient blue light-emi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hiroshi Amano</td>\n",
       "      <td>Japan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Shuji Nakamura</td>\n",
       "      <td>Japan\\n United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2015</td>\n",
       "      <td>Takaaki Kajita</td>\n",
       "      <td>Japan</td>\n",
       "      <td>\"for the discovery of neutrino oscillations, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Arthur B. McDonald</td>\n",
       "      <td>Canada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2016</td>\n",
       "      <td>David J. Thouless</td>\n",
       "      <td>United Kingdom\\n United States</td>\n",
       "      <td>\"for theoretical discoveries of topological ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>F. Duncan M. Haldane</td>\n",
       "      <td>United Kingdom\\n United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>John M. Kosterlitz</td>\n",
       "      <td>United Kingdom\\n United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year                      Laureate[A]  \\\n",
       "0    1901           Wilhelm Conrad Röntgen   \n",
       "1    1902                  Hendrik Lorentz   \n",
       "2     NaN                    Pieter Zeeman   \n",
       "3    1903          Antoine Henri Becquerel   \n",
       "4     NaN                     Pierre Curie   \n",
       "5     NaN           Maria Skłodowska-Curie   \n",
       "6    1904                    Lord Rayleigh   \n",
       "7    1905  Philipp Eduard Anton von Lenard   \n",
       "8    1906              Joseph John Thomson   \n",
       "9    1907         Albert Abraham Michelson   \n",
       "10   1908                 Gabriel Lippmann   \n",
       "11   1909                Guglielmo Marconi   \n",
       "12    NaN             Karl Ferdinand Braun   \n",
       "13   1910   Johannes Diderik van der Waals   \n",
       "14   1911                     Wilhelm Wien   \n",
       "15   1912                Nils Gustaf Dalén   \n",
       "16   1913           Heike Kamerlingh-Onnes   \n",
       "17   1914                     Max von Laue   \n",
       "18   1915              William Henry Bragg   \n",
       "19    NaN           William Lawrence Bragg   \n",
       "20   1916          Not awarded World War I   \n",
       "21   1917            Charles Glover Barkla   \n",
       "22   1918                       Max Planck   \n",
       "23   1919                   Johannes Stark   \n",
       "24   1920        Charles Édouard Guillaume   \n",
       "25   1921                  Albert Einstein   \n",
       "26   1922                       Niels Bohr   \n",
       "27   1923          Robert Andrews Millikan   \n",
       "28   1924                   Manne Siegbahn   \n",
       "29   1925                     James Franck   \n",
       "..    ...                              ...   \n",
       "180  2005                   Roy J. Glauber   \n",
       "181   NaN                     John L. Hall   \n",
       "182   NaN                Theodor W. Hänsch   \n",
       "183  2006                   John C. Mather   \n",
       "184   NaN                  George F. Smoot   \n",
       "185  2007                      Albert Fert   \n",
       "186   NaN                   Peter Grünberg   \n",
       "187  2008                 Makoto Kobayashi   \n",
       "188   NaN                Toshihide Maskawa   \n",
       "189   NaN                   Yoichiro Nambu   \n",
       "190  2009                   Charles K. Kao   \n",
       "191   NaN                 Willard S. Boyle   \n",
       "192   NaN                  George E. Smith   \n",
       "193  2010                       Andre Geim   \n",
       "194   NaN             Konstantin Novoselov   \n",
       "195  2011                  Saul Perlmutter   \n",
       "196   NaN                 Brian P. Schmidt   \n",
       "197   NaN                    Adam G. Riess   \n",
       "198  2012                    Serge Haroche   \n",
       "199   NaN                David J. Wineland   \n",
       "200  2013                 François Englert   \n",
       "201   NaN                      Peter Higgs   \n",
       "202  2014                    Isamu Akasaki   \n",
       "203   NaN                    Hiroshi Amano   \n",
       "204   NaN                   Shuji Nakamura   \n",
       "205  2015                   Takaaki Kajita   \n",
       "206   NaN               Arthur B. McDonald   \n",
       "207  2016                David J. Thouless   \n",
       "208   NaN             F. Duncan M. Haldane   \n",
       "209   NaN               John M. Kosterlitz   \n",
       "\n",
       "                                     Country[B]  \\\n",
       "0                                       Germany   \n",
       "1                                   Netherlands   \n",
       "2                                   Netherlands   \n",
       "3                                        France   \n",
       "4                                        France   \n",
       "5                               Poland\\n France   \n",
       "6                                United Kingdom   \n",
       "7                     Austria-Hungary\\n Germany   \n",
       "8                                United Kingdom   \n",
       "9                        United States\\n Poland   \n",
       "10                                       France   \n",
       "11                                        Italy   \n",
       "12                                      Germany   \n",
       "13                                  Netherlands   \n",
       "14                                      Germany   \n",
       "15                                       Sweden   \n",
       "16                                  Netherlands   \n",
       "17                                      Germany   \n",
       "18                               United Kingdom   \n",
       "19                   Australia\\n United Kingdom   \n",
       "20                                         None   \n",
       "21                               United Kingdom   \n",
       "22                                      Germany   \n",
       "23                                      Germany   \n",
       "24                                  Switzerland   \n",
       "25                       Germany\\n  Switzerland   \n",
       "26                                      Denmark   \n",
       "27                                United States   \n",
       "28                                       Sweden   \n",
       "29                                      Germany   \n",
       "..                                          ...   \n",
       "180                               United States   \n",
       "181                               United States   \n",
       "182                                     Germany   \n",
       "183                               United States   \n",
       "184                               United States   \n",
       "185                                      France   \n",
       "186                                     Germany   \n",
       "187                                       Japan   \n",
       "188                                       Japan   \n",
       "189                       Japan\\n United States   \n",
       "190  Hong Kong\\n United Kingdom\\n United States   \n",
       "191                      Canada\\n United States   \n",
       "192                               United States   \n",
       "193       Russia\\n United Kingdom\\n Netherlands   \n",
       "194                     Russia\\n United Kingdom   \n",
       "195                               United States   \n",
       "196                   Australia\\n United States   \n",
       "197                               United States   \n",
       "198                                      France   \n",
       "199                               United States   \n",
       "200                                     Belgium   \n",
       "201                              United Kingdom   \n",
       "202                                       Japan   \n",
       "203                                       Japan   \n",
       "204                       Japan\\n United States   \n",
       "205                                       Japan   \n",
       "206                                      Canada   \n",
       "207              United Kingdom\\n United States   \n",
       "208              United Kingdom\\n United States   \n",
       "209              United Kingdom\\n United States   \n",
       "\n",
       "                                          Rationale[C]  \n",
       "0    \"in recognition of the extraordinary services ...  \n",
       "1    \"in recognition of the extraordinary service t...  \n",
       "2                                                 None  \n",
       "3    \"for his discovery of spontaneous radioactivit...  \n",
       "4    \"for their joint researches on the radiation p...  \n",
       "5                                                 None  \n",
       "6    \"for his investigations of the densities of th...  \n",
       "7                   \"for his work on cathode rays\"[11]  \n",
       "8    \"for his theoretical and experimental investig...  \n",
       "9    \"for his optical precision instruments and the...  \n",
       "10   \"for his method of reproducing colours photogr...  \n",
       "11   \"for their contributions to the development of...  \n",
       "12                                                None  \n",
       "13   \"for his work on the equation of state for gas...  \n",
       "14   \"for his discoveries regarding the laws govern...  \n",
       "15   \"for his invention of automatic valves designe...  \n",
       "16   \"for his investigations on the properties of m...  \n",
       "17   \"For his discovery of the diffraction of X-ray...  \n",
       "18   \"For their services in the analysis of crystal...  \n",
       "19                                                None  \n",
       "20                                                None  \n",
       "21   \"For his discovery of the characteristic Röntg...  \n",
       "22   \"for the services he rendered to the advanceme...  \n",
       "23   \"for his discovery of the Doppler effect in ca...  \n",
       "24   \"for the service he has rendered to precision ...  \n",
       "25   \"for his services to theoretical physics, and ...  \n",
       "26   \"for his services in the investigation of the ...  \n",
       "27   \"for his work on the elementary charge of elec...  \n",
       "28   \"for his discoveries and research in the field...  \n",
       "29   \"for their discovery of the laws governing the...  \n",
       "..                                                 ...  \n",
       "180  \"for his contribution to the quantum theory of...  \n",
       "181  \"for their contributions to the development of...  \n",
       "182                                               None  \n",
       "183  \"for their discovery of the blackbody form and...  \n",
       "184                                               None  \n",
       "185  \"for the discovery of giant magnetoresistance\"...  \n",
       "186                                               None  \n",
       "187  \"for the discovery of the origin of the broken...  \n",
       "188                                               None  \n",
       "189  \"for the discovery of the mechanism of spontan...  \n",
       "190  \"for groundbreaking achievements concerning th...  \n",
       "191  \"for the invention of an imaging semiconductor...  \n",
       "192                                               None  \n",
       "193  \"for groundbreaking experiments regarding the ...  \n",
       "194                                               None  \n",
       "195  \"for the discovery of the accelerating expansi...  \n",
       "196                                               None  \n",
       "197                                               None  \n",
       "198  \"for ground-breaking experimental methods that...  \n",
       "199                                               None  \n",
       "200  \"for the theoretical discovery of a mechanism ...  \n",
       "201                                               None  \n",
       "202  \"for the invention of efficient blue light-emi...  \n",
       "203                                               None  \n",
       "204                                               None  \n",
       "205  \"for the discovery of neutrino oscillations, w...  \n",
       "206                                               None  \n",
       "207  \"for theoretical discoveries of topological ph...  \n",
       "208                                               None  \n",
       "209                                               None  \n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line to ensure the use of plots within Jupyter\n",
    "%matplotlib inline\n",
    "# We import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from httplib2 import Http\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "class Parser:\n",
    "    \n",
    "    def __init__(self, url):  \n",
    "        http = Http()\n",
    "        status, response = http.request(url)\n",
    "        tables = BeautifulSoup(response, \"lxml\", \n",
    "                              parse_only=SoupStrainer(\"table\", {\"class\":\"wikitable sortable\"}))\n",
    "        self.table = tables.contents[1]\n",
    "    \n",
    "    def parse_table(self):      \n",
    "        rows = self.table.find_all(\"tr\")\n",
    "        header = self.parse_header(rows[0])\n",
    "        table_array = [self.parse_row(row) for row in rows[1:]]\n",
    "        table_df = pd.DataFrame(table_array, columns=header).apply(self.clean_table, 1)\n",
    "        return table_df.replace({\"Year\":{'':np.nan}})\n",
    "        \n",
    "    def parse_row(self, row):     \n",
    "        columns = row.find_all(\"td\")\n",
    "        return [BeautifulSoup.get_text(col).strip() for col in columns if BeautifulSoup.get_text(col) != '']\n",
    "    \n",
    "    def parse_header(self, row):     \n",
    "        columns = row.find_all(\"th\")\n",
    "        return [BeautifulSoup.get_text(col).strip() for col in columns if BeautifulSoup.get_text(col) != \"\"]\n",
    "    \n",
    "    def clean_table(self, row):\n",
    "        if not row.iloc[0].isdigit() and row.iloc[0] != '':\n",
    "            return row.shift(1)\n",
    "        else:\n",
    "            return row\n",
    "        \n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Physics\"        \n",
    "parser = Parser(url)   \n",
    "nobel_df = parser.parse_table()\n",
    "nobel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "As you can see the data is a bit messy so we need to clean a bit. We need to:\n",
    "\n",
    ">- clean the columns names by changing them to: \"Year\", \"Laureate\", \"Country\", \"Rationale\".\n",
    "- remove the rows that where the Nobel price was not awarded (the ones with missing values). You can use the [`pd.dropna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) function with the argument `subset`.\n",
    "- fill the missing values in the year and rational columns. You can use the [`pd.fillna`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html) function with the argument `method='ffill'` (you can do that here because the rows are ordered by date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Clean the columns names\n",
    "\n",
    "# TODO: drop all the rows where the nobel price was not awarded\n",
    "\n",
    "# TODO: fill the missing values in the year column\"\n",
    "\n",
    "# Is your data clean?\n",
    "nobel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets check that our data set does not contain missing values anymore\n",
    "nobel_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some questions about this data\n",
    "\n",
    "Let's answer few questions about this data (with codes). \n",
    "\n",
    ">- How many physicists got a Nobel price? Be careful about possible duplicates. You can look at the [`pd.nunique()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nunique.html) function.\n",
    "- How many countries are in this data set? Be careful about possible duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: How many physicists got a nobel price?\n",
    "physicist_number =  # YOUR CODE\n",
    "\n",
    "# TODO: How many countries are in this data set?\n",
    "country_number =  # YOUR CODE\n",
    "\n",
    "print(physicist_number)\n",
    "print(country_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you have noticed that some values for the Column \"Country\" are represented by 2 countries separated by a return character (i.e. \"Austria-Hungary\\n Germany\"). Let's try to observe the distribution of countries in this data set.\n",
    "\n",
    ">- Use the [`pandas.Series.str.split`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html) function to split the column \"Country\" into a column \"Country_list\" of lists of countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: split the column \"Country\" into a column \"Country_list\" of lists of countries\n",
    "nobel_df[\"Country_list\"] =  # YOUR CODE\n",
    "\n",
    "# We create a pandas series from this new column to ease the analysis on the countries. The sum on list is used to \n",
    "# flatten the list of lists into one list of countries.\n",
    "countries = pd.Series(sum(nobel_df[\"Country_list\"].tolist(), [])).str.strip()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of countries:\n",
    ">- Print the countries with the number of time it is contained in the `countries` pandas Series. You can use the [`pd.Series.value_counts`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html) function.\n",
    "- Plot a barplot ordered by those number. You can use the function [`pd.plot`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) by changing the argument `kind`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: print the countries and the number of times they are contained in the countries pandas Series. It should\n",
    "# be printed ordered by the number of times they are contained in the countries pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Plot a barplot ordered by those number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What type of physics those physicists are practicing?\n",
    "\n",
    "Let's try to gather some data to understand what type of physics is associated to each of those physicists. Ultimately we want to extract the words that are characteristics of each physicist.\n",
    "\n",
    "We extract the webpage links to have access to their bibliography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from httplib2 import Http\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "http = Http()\n",
    "status, response = http.request(url)\n",
    "\n",
    "table = BeautifulSoup(response, \"lxml\", parse_only=SoupStrainer('table'))\n",
    "link_df = pd.DataFrame([[x.string, x[\"href\"]] for x in table.contents[1].find_all(\"a\")],\n",
    "                       columns=[\"Text\", \"link\"]).drop_duplicates()\n",
    "\n",
    "link_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need now to merge this table to the `nobel_df` table. Use the [`pandas.DataFrame.merge`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) or  [`pandas.concat`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html) function to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: merge nobel_df and link_df into nobel_merged_df\n",
    "nobel_merged_df =  # YOUR CODE\n",
    "nobel_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Did the merging completely work? Are there some missing values? If yes correct it\n",
    "\n",
    "Now we are going to extract all the words in the Wikipedia page of each of those physicists. The following function `get_text` will extract the text of a Wikipedia page as a long string. \n",
    "\n",
    ">Use it to extract every text for each of the physicists into the columns \"Bio\". Use the function [`apply`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html) to vectorize your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Will Extract the text associated to every link\n",
    "def get_text(link, root_website = \"https://en.wikipedia.org\"):    \n",
    "    http = Http()\n",
    "    status, response = http.request(root_website + link)\n",
    "\n",
    "    body = BeautifulSoup(response, \"lxml\", parse_only=SoupStrainer(\"div\", {\"id\":\"mw-content-text\"}))\n",
    "    return BeautifulSoup.get_text(body.contents[1])\n",
    "\n",
    "nobel_merged_df.set_index(\"Laureate\", inplace=True)\n",
    "\n",
    "# TODO: extract the text of the wikipedia page associated to each physicist\n",
    "nobel_merged_df[\"Bio\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Bio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remove all the punctuation along with the number and set all the words to lower case. We import the punctuation package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an example of how to remove punctuation and the numbers for one bio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in punctuation + \"1234567890\":\n",
    "    nobel_merged_df[\"Bio\"][0] = nobel_merged_df[\"Bio\"][0].replace(p,'').lower()  \n",
    "    \n",
    "nobel_merged_df[\"Bio\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Write a function and then use the pandas `apply` to treat all the bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: write a function that remove the punctuation and numbers and set every word to lower case\n",
    "def clean_string(string):\n",
    "    # TODO: your code goes here\n",
    "    pass\n",
    "\n",
    "# TODO: apply this function to the \"Bio\" column\n",
    "nobel_merged_df[\"Bio\"] =  # YOUR CODE  \n",
    "nobel_merged_df[\"Bio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Use the `str.split` function again to split each text on any whitespace character (i.e \"\\s\") into the \"Bio_split\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: split the \"Bio\" column as a column of lists of the words \n",
    "nobel_merged_df[\"Bio_list\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Bio_list\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are a lot of empty elements in each of those lists. We can remove those using the [`filter`](http://book.pythontips.com/en/latest/map_filter.html) function or a comprehension list along with the `apply` function. \n",
    "\n",
    ">- Write a function that removes `None` elements from a list\n",
    "- apply that function to the \"Bio_list\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Write a function that removes `None` elements from a list\n",
    "def remove(list_to_clean, element_to_remove=[None, \"\"]):\n",
    "    # TODO: your code goes here\n",
    "    pass\n",
    "\n",
    "# TODO: apply that function to the \"Bio_list\" columns\n",
    "nobel_merged_df[\"Bio_list\"] =  # YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the [`nltk`](http://www.nltk.org/) library to help us clean this data. Be sure to install the library with `pip` or `conda`.\n",
    "\n",
    "Use the `nltk.download('stopwords')` function to download the stopwords corpus. A you can see, the stopwords are common english words that do not carry significant information of a specific text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to capture in each bag of words, the words that are characteristic of a specific physicist. There are many words in the english language that are not useful for that. We call those words the stopwords.\n",
    "\n",
    "> Use your `remove` function to remove those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "words_to_remove = set(stopwords.words('english'))\n",
    "\n",
    "# TODO: remove the stop words\n",
    "nobel_merged_df[\"Bio_list\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Bio_list\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Write a function that removes the words that have only one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: write a function that removes the words that have only one character\n",
    "def remove_one(list_to_clean):\n",
    "    pass\n",
    "\n",
    "# TODO: apply this function to the \"bio_list\" column\n",
    "nobel_merged_df[\"Bio_list\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Bio_list\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remove all the words that appear too few times. This is an attempt to filter the words that are not relevant to the particular physics at play\n",
    "\n",
    "> Write a function that removes all the words under a certain amount of occurance. I would say that it is job to choose the threshold (if any!) on the number of occurance that you feel gives you satisfying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: write a function that remove all the words under a certain amount of occurance\n",
    "def remove_n_occurrance(list_to_clean, n = 1):\n",
    "    pass \n",
    " \n",
    "# TODO: apply this function to the \"bio_list\" column\n",
    "nobel_merged_df[\"Bio_list\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Bio_list\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are just going to keep each word once and remove the duplicate. You can use the function `set` to do so\n",
    "\n",
    "> Write a function that remove the duplicated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: write a function that keeps only each element of a list only once\n",
    "def remove_duplicates(list_to_clean):\n",
    "    pass\n",
    "\n",
    "# TODO: apply this function to the \"bio_list\" column\n",
    "nobel_merged_df[\"Bio_list\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Bio_list\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now are going to try to guess from this data, what type of physics those physicists are practicing. [Wikipedia](https://en.wikipedia.org/wiki/Physics) identifies 6 types of physics (to be debated!): [Nuclear physics](https://en.wikipedia.org/wiki/Nuclear_physics), [particle physics](https://en.wikipedia.org/wiki/Particle_physics), [Atomic, molecular, and optical physics](https://en.wikipedia.org/wiki/Atomic,_molecular,_and_optical_physics), [Condensed matter physics](https://en.wikipedia.org/wiki/Condensed_matter_physics), [Astrophysics](https://en.wikipedia.org/wiki/Astrophysics) and [Physical_cosmology](https://en.wikipedia.org/wiki/Physical_cosmology). We are going to get the text data from those pages and look at the set of words that are 2 different pages.\n",
    "\n",
    "> Use your previously written functions to clean those the content from those Wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physics_df = pd.DataFrame({\"Field\": [\"Nuclear physics\",\n",
    "                                     \"Particle physics\", \n",
    "                                     \"Atomic, molecular, and optical physics\", \n",
    "                                     \"Condensed matter physics\", \n",
    "                                     \"Astrophysics\",\n",
    "                                     \"Physical_cosmology\"],\n",
    "                           \"link\": [\"/wiki/Nuclear_physics\",\n",
    "                                     \"/wiki/Particle_physics\", \n",
    "                                     \"/wiki/Atomic,_molecular,_and_optical_physics\", \n",
    "                                     \"/wiki/Condensed_matter_physics\", \n",
    "                                     \"/wiki/Astrophysics\",\n",
    "                                     \"/wiki/Physical_cosmology\"]})\n",
    "\n",
    "physics_df.set_index(\"Field\", inplace=True)\n",
    "\n",
    "# TODO: gather and clean the data related to those physics fields wikipedia pages\n",
    "physics_df[\"Text_data\"] =  # YOUR CODE\n",
    "\n",
    "physics_df[\"Text_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">For each physicist compute the number of words in his biography that intersect with the physics fields pages. You can use the function [`intersection`](https://docs.python.org/2/library/sets.html) of the `set` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "list1 = [1, 2, 3, 4]\n",
    "list2 = [3, 4, 5, 6]\n",
    "set(list1).intersection(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Write a function that count the number of words that intersect between two lists\n",
    "def intesect_count(list1, list2):\n",
    "    pass\n",
    "\n",
    "# TODO: create those columns\n",
    "nobel_merged_df[\"Count_intersect_Nuclear\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_intersect_Particle\"] =   # YOUR CODE\n",
    "nobel_merged_df[\"Count_intersect_Atomic\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_intersect_Condensed\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_intersect_Astrophysics\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_intersect_Cosmology\"] =  # YOUR CODE\n",
    "\n",
    "nobel_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">For each physicist compute the total number of words contained in his biography and in each of the physics fields pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Write a function that count the total number of unique words contained in two lists\n",
    "def total_count(list1, list2):\n",
    "    pass\n",
    "\n",
    "# TODO: create those columns\n",
    "nobel_merged_df[\"Count_total_Nuclear\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_total_Particle\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_total_Atomic\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_total_Condensed\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_total_Astrophysics\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Count_total_Cosmology\"] =  # YOUR CODE\n",
    "\n",
    "nobel_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to estimate the probability for words to belong to the wikipedia page of a physicist and to a physics field page using the following approximation:\n",
    "\\begin{equation}\n",
    "p(\\mbox{Same words for physicist P and field F}) \\simeq \\frac{\\mbox{Number of words in P and in F}}{\\mbox{Total number of words contained in P and F}}= \\frac{P\\cap F}{P\\cup F}\n",
    "\\end{equation} \n",
    "This \"probability\" is known as the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index).\n",
    "\n",
    ">For each physicist, compute the Jaccard index for words to be in both the physicist page and each physics field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Compute those columns\n",
    "nobel_merged_df[\"Proba_Nuclear\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Proba_Particle\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Proba_Atomic\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Proba_Condensed\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Proba_Astrophysics\"] =  # YOUR CODE\n",
    "nobel_merged_df[\"Proba_Cosmology\"] =  # YOUR CODE\n",
    "\n",
    "nobel_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Use the [`pd.idxmax`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.idxmax.html) to capture what field has the highest probability of intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba_cols = [\"Proba_Nuclear\",\n",
    "              \"Proba_Particle\",\n",
    "              \"Proba_Atomic\",\n",
    "              \"Proba_Condensed\",\n",
    "              \"Proba_Astrophysics\",\n",
    "              \"Proba_Cosmology\"]\n",
    "\n",
    "# We normalize the probability to 1\n",
    "nobel_merged_df[proba_cols] = nobel_merged_df[proba_cols].apply(lambda x: x / sum(x), 1)\n",
    "\n",
    "# TODO: Which field each physicist belongs to? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Do you agree with this classification? How could we improve the analysis to get better classification?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
