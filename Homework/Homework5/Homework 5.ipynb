{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Training a classifier\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this homework, you will have the opportunity to train your best classifier on a data set provided on Kaggle for a current competition: \n",
    "https://www.kaggle.com/c/porto-seguro-safe-driver-prediction \n",
    "\n",
    "The data has slightly been transformed from its original form and down-sampled but you can find a description of the data here:\n",
    "https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data\n",
    "\n",
    "You can also find inspiration on how to improve your model here:\n",
    "https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/kernels\n",
    "\n",
    "The \"id\" column is a unique identifier and has to be used as an index. The columns you want to predict is the column \"target\". All the other columns can be used in training.\n",
    "\n",
    "## The files\n",
    "\n",
    "You will 3 files with this homework:\n",
    "- train_data.csv\n",
    "- test_data.csv\n",
    "- submission_example.csv\n",
    "\n",
    "The first file will be used for training and contains all the attributes, the target and a unique identifier. The second file will be used to assess your classifier and contains only the attributes along with a unique identifier. The last file is an example of a submission.\n",
    "\n",
    "## Machine Learning Libraries \n",
    "\n",
    "There are many Machine Learning (ML) Libraries available for python. The most known one is obviously [scikit-learn](http://scikit-learn.org/stable/supervised_learning.html) where many classifier algorithms are available for you to try. Currently [XGBoost](http://xgboost.readthedocs.io/en/latest/python/python_intro.html), [LightGBM](https://github.com/Microsoft/LightGBM) and [H2O](http://h2o-release.s3.amazonaws.com/h2o/rel-weierstrass/7/index.html) are amount the best performing ML libraries for supervised learning tasks. You are invited and advised to try all packages to find what works best for the data in this homework. \n",
    "\n",
    "Very popular, are also all the Artificial Neural Network libraries that can be more difficult to tame:\n",
    "- [TensorFlow](https://www.tensorflow.org/)\n",
    "- [Pytorch](http://pytorch.org/)\n",
    "- [Keras](https://keras.io/)\n",
    "- [MXNet](http://mxnet.incubator.apache.org/)\n",
    "- ...\n",
    "\n",
    "## Training a Classifier\n",
    "\n",
    "When it comes training a classifier there are different techniques to consider to improving performance:\n",
    "- Tuning the hyperparameters: find the right algorithm parameters. \n",
    "- Features selection: filter away the features that may be detrimental to the performance.\n",
    "- Data transformation: transform the data to make it easier for a learner to learn from. \n",
    "- Features augmentation: create new features from the old ones.\n",
    "- ...\n",
    "\n",
    "It will be important for you to cross-validate your results to find the optimal parameters and features. There are many functions in scikit-learn that can help you achieve that:\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) are two examples of functions that can help you tune your models\n",
    "- Scikit-learn has a variety of methods for [feature selection](http://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "- There are many ways to [preprocess a data set](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features). [Box-cox transformation](https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.stats.boxcox.html) is also a classic method.\n",
    "- It can be interesting to use unsupervised learning techniques to [create new features](http://scikit-learn.org/stable/unsupervised_learning.html)\n",
    "\n",
    "Fundamental problems you will need to solve when it comes to preprocessing the data is to find a way to deal with missing values and categorical variables.\n",
    "\n",
    "## The grading\n",
    "\n",
    "The grading will be two parts:\n",
    "- In the first part, you will explain in details what you have tried and what got you your best performance. You will describe the difficulties you encountered and how you solved them. The format of this small report does not need to be fancy. (10 points) \n",
    "- The second part, you will submit your predictions of a test set. You will be able to submit as many times as you want and only your best score will be retained. The performance will be assessed with AUC. (10 points)\n",
    "\n",
    "To establish your grade of the second part, rules of the game are simple. This following code\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "train_df = pd.read_csv(\"./train_data.csv\", index_col=[\"id\"])\n",
    "test_X = pd.read_csv(\"./test_data.csv\", index_col=[\"id\"])\n",
    "test_Y = pd.read_csv(\"./test_target.csv\", index_col=[\"id\"])\n",
    "\n",
    "col_cat = train_df.select_dtypes(include=[object]).columns\n",
    "for col in col_cat:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].fillna(\"-1\"))\n",
    "    test_X[col] = le.transform(test_X[col].fillna(\"-1\"))\n",
    "    \n",
    "train_df.fillna(-1, inplace=True)\n",
    "test_X.fillna(-1, inplace=True)\n",
    "\n",
    "clf = LogisticRegression(n_jobs=-1, C=1e6)\n",
    "y_train = train_df[\"target\"]\n",
    "X_train =  train_df.drop(\"target\", 1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "metrics.roc_auc_score(test_Y, clf.predict_proba(test_X)[:, 1])\n",
    "```\n",
    "\n",
    "yields a AUC = 0.619522. If you get this AUC or lower you get 0 points. After a quick but more in-depth train, I was able to obtain AUC = 0.64486707. If you get this AUC or higher, you get the full points. Every intermediary performance will give you an intermediary grade according to the following scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Intervals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.619522, 0.622338]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.622338, 0.625154]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.625154, 0.62797]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(0.62797, 0.630786]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>(0.630786, 0.633603]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.633603, 0.636419]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.636419, 0.639235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>(0.639235, 0.642051]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>(0.642051, 0.644867]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grade             Intervals\n",
       "0    1.0  (0.619522, 0.622338]\n",
       "1    2.0  (0.622338, 0.625154]\n",
       "2    3.0   (0.625154, 0.62797]\n",
       "3    4.0   (0.62797, 0.630786]\n",
       "4    5.0  (0.630786, 0.633603]\n",
       "5    6.0  (0.633603, 0.636419]\n",
       "6    7.0  (0.636419, 0.639235]\n",
       "7    8.0  (0.639235, 0.642051]\n",
       "8    9.0  (0.642051, 0.644867]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "bins = np.linspace(0.619522, 0.64486707, 10)\n",
    "mean_bins = (bins[1:] +  bins[:-1]) / 2\n",
    "pd.DataFrame({\"Intervals\": pd.cut(mean_bins, bins, precision=6), \"Grade\": rankdata(mean_bins)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyday, I will publish on Piazza your best performance to see where you stand.\n",
    "\n",
    "## Submission\n",
    "\n",
    "You will need to submit a .csv file with exactly the following format (you can see the example in the current folder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "train_df = pd.read_csv(\"./train_data.csv\", index_col=[\"id\"])\n",
    "test_X = pd.read_csv(\"./test_data.csv\", index_col=[\"id\"])\n",
    "\n",
    "col_cat = train_df.select_dtypes(include=[object]).columns\n",
    "for col in col_cat:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].fillna(\"-1\"))\n",
    "    test_X[col] = le.transform(test_X[col].fillna(\"-1\"))\n",
    "\n",
    "train_df.fillna(-1, inplace=True)\n",
    "test_X.fillna(-1, inplace=True)\n",
    "\n",
    "clf = LogisticRegression(n_jobs=-1, C=1e6)\n",
    "y_train = train_df[\"target\"]\n",
    "X_train =  train_df.drop(\"target\", 1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "submission_example = pd.DataFrame({\"prediction\": clf.predict_proba(test_X)[:, 1]}, index=test_X.index) \n",
    "submission_example.to_csv(\"./submission_example.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
